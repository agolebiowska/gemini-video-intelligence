{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59fcb2a4-59bc-4ee4-8628-bd4745c29760",
   "metadata": {},
   "source": [
    "# Key moments extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "FwnQCw0Y9yV2NgDHjQ26QPWf",
   "metadata": {
    "executionInfo": {
     "elapsed": 10457,
     "status": "ok",
     "timestamp": 1739352007907,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "FwnQCw0Y9yV2NgDHjQ26QPWf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from video_intelligence.utils import io\n",
    "from video_intelligence.config import Config\n",
    "from video_intelligence.export.bq import BigQueryExporter\n",
    "from video_intelligence.processing.sequences import SequenceProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df656ddb-8402-4fbb-b6bd-9c7d7b01e76c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_file = str(Path.cwd().parent / \"config.yaml\")\n",
    "config = Config.from_yaml(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdf8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_io = io.GcsIO(config.project_id, f\"gs://{config.bucket}\")\n",
    "local_io = io.LocalIO(root_path=config.paths.tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa75cd2-a9d3-4033-9973-9c374e7cd1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "videos = gcs_io.list_files(path=config.preprocessed_path, rec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d6024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SequenceProcessor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5641cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for gcs_path in videos:\n",
    "    video_bytes = gcs_io.get_video(path=gcs_path)\n",
    "    detections = processor._get_detections_from_bq(gcs_path)\n",
    "    response = processor.extract_sequences(\n",
    "        video_bytes, detections\n",
    "    )\n",
    "    results[gcs_path] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "512f7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.paths.sequences, \"w\") as f:\n",
    "    f.write(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03304ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequences data from /usr/local/google/home/gagata/code/video-intelligence/results/results.json\n",
      "Prepared sequences for preprocessed/0000f77c-6257be58/0000f77c-6257be58.mp4\n",
      "Prepared sequences for preprocessed/00225f53-67614580/00225f53-67614580.mp4\n",
      "Prepared sequences for preprocessed/00091078-7cff8ea6/00091078-7cff8ea6.mp4\n",
      "Loading 3 updated records to BigQuery...\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details.; reason: invalid, message: Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details.; reason: invalid, message: Error while reading data, error message: JSON processing encountered too many errors, giving up. Rows: 1; errors: 1; max bad: 0; error percent: 0; reason: invalid, message: Error while reading data, error message: JSON parsing error in row starting at position 0: No such field: sequences.timestamp.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m exporter \u001b[38;5;241m=\u001b[39m BigQueryExporter(config)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mexporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/video-intelligence/video_intelligence/export/bq.py:255\u001b[0m, in \u001b[0;36mBigQueryExporter.export_sequences\u001b[0;34m(self, sequences_file)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(sequences_jsonl, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m source_file:\n\u001b[1;32m    251\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mload_table_from_file(\n\u001b[1;32m    252\u001b[0m         source_file, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_id, job_config\u001b[38;5;241m=\u001b[39mjob_config\n\u001b[1;32m    253\u001b[0m     )\n\u001b[0;32m--> 255\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m Path(sequences_jsonl)\u001b[38;5;241m.\u001b[39munlink()\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll sequences exported successfully to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/video-intelligence-w_Sfx2-O-py3.11/lib/python3.11/site-packages/google/cloud/bigquery/job/base.py:969\u001b[0m, in \u001b[0;36m_AsyncJob.result\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    968\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m DEFAULT_RETRY \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m\"\u001b[39m: retry}\n\u001b[0;32m--> 969\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AsyncJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/video-intelligence-w_Sfx2-O-py3.11/lib/python3.11/site-packages/google/api_core/future/polling.py:261\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_poll(timeout\u001b[38;5;241m=\u001b[39mtimeout, retry\u001b[38;5;241m=\u001b[39mretry, polling\u001b[38;5;241m=\u001b[39mpolling)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details.; reason: invalid, message: Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details.; reason: invalid, message: Error while reading data, error message: JSON processing encountered too many errors, giving up. Rows: 1; errors: 1; max bad: 0; error percent: 0; reason: invalid, message: Error while reading data, error message: JSON parsing error in row starting at position 0: No such field: sequences.timestamp."
     ]
    }
   ],
   "source": [
    "exporter = BigQueryExporter(config)\n",
    "exporter.export_sequences(config.paths.results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "iasmaa (Feb 10, 2025, 10:10:41â€¯AM)",
   "provenance": []
  },
  "environment": {
   "kernel": "raidar",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "video-intelligence-w_Sfx2-O-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
